# Gu√≠a: ANOVA (An√°lisis de Varianza)

## üéØ ¬øQu√© es ANOVA?

**ANOVA (Analysis of Variance)** es una prueba estad√≠stica para comparar las **medias de 3 o m√°s grupos** simult√°neamente.

**Ejemplo de negocio:**
> ¬øLa satisfacci√≥n promedio es diferente entre las 4 √°reas de servicio (Norte, Sur, Este, Oeste)?

---

## üìã ¬øPor qu√© ANOVA y no m√∫ltiples pruebas t?

### Problema con m√∫ltiples pruebas t:

Si tienes 4 grupos y quieres compararlos todos:
- Norte vs Sur
- Norte vs Este
- Norte vs Oeste
- Sur vs Este
- Sur vs Oeste
- Este vs Oeste

**Total: 6 pruebas t**

**Problema:** Cada prueba tiene 5% de probabilidad de Error Tipo I (Œ±=0.05). Con m√∫ltiples pruebas, la probabilidad acumulada de cometer al menos un error aumenta significativamente.

**Soluci√≥n:** ANOVA controla el error Tipo I al hacer UNA sola prueba para todos los grupos.

---

## üßÆ ANOVA de Un Factor (One-Way ANOVA)

### Hip√≥tesis:

- **H‚ÇÄ:** Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = ... = Œº‚Çñ (Todas las medias son iguales)
- **H‚ÇÅ:** Al menos una media es diferente

### Paso 1: Verificar Supuestos

#### 1. Independencia de observaciones
Cada observaci√≥n es independiente de las dem√°s.

#### 2. Normalidad
Los datos de cada grupo siguen una distribuci√≥n normal.

**Prueba de Shapiro-Wilk:**
```python
from scipy.stats import shapiro

for area in df['area'].unique():
    datos = df[df['area'] == area]['satisfaccion']
    stat, p = shapiro(datos)
    print(f"{area}: W={stat:.4f}, p={p:.4f}")
    if p > 0.05:
        print("  ‚úì Normal")
    else:
        print("  ‚úó No normal")
```

#### 3. Homogeneidad de varianzas (Homocedasticidad)
Las varianzas de los grupos son similares.

**Prueba de Levene:**
```python
from scipy.stats import levene

grupos = [df[df['area'] == area]['satisfaccion'] for area in df['area'].unique()]
stat, p = levene(*grupos)

print(f"Test de Levene: W={stat:.4f}, p={p:.4f}")
if p > 0.05:
    print("‚úì Varianzas homog√©neas")
else:
    print("‚úó Varianzas NO homog√©neas (considerar Welch's ANOVA)")
```

---

## üíª Implementaci√≥n en Python

### Opci√≥n 1: Usando scipy

```python
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar datos
df = pd.read_csv('datos_satisfaccion.csv')

# Separar datos por grupo
norte = df[df['area'] == 'Norte']['satisfaccion']
sur = df[df['area'] == 'Sur']['satisfaccion']
este = df[df['area'] == 'Este']['satisfaccion']
oeste = df[df['area'] == 'Oeste']['satisfaccion']

# Realizar ANOVA
f_stat, p_value = stats.f_oneway(norte, sur, este, oeste)

print("="*60)
print("ANOVA DE UN FACTOR")
print("="*60)
print(f"F-statistic: {f_stat:.4f}")
print(f"p-value: {p_value:.4f}")

# Decisi√≥n
alpha = 0.05
if p_value < alpha:
    print(f"\n‚úó Rechazamos H‚ÇÄ (p={p_value:.4f} < {alpha})")
    print("Conclusi√≥n: Al menos una media es diferente")
    print("Siguiente paso: Pruebas post-hoc para identificar cu√°l(es)")
else:
    print(f"\n‚úì No rechazamos H‚ÇÄ (p={p_value:.4f} ‚â• {alpha})")
    print("Conclusi√≥n: No hay diferencia significativa entre las medias")
```

### Opci√≥n 2: Usando statsmodels (con tabla ANOVA completa)

```python
import statsmodels.api as sm
from statsmodels.formula.api import ols

# Ajustar modelo ANOVA
modelo = ols('satisfaccion ~ C(area)', data=df).fit()

# Tabla ANOVA
tabla_anova = sm.stats.anova_lm(modelo, typ=2)
print("\nTabla ANOVA:")
print(tabla_anova)

# Explicaci√≥n de la tabla:
# sum_sq: Suma de cuadrados
# df: Grados de libertad
# F: Estad√≠stico F
# PR(>F): p-value
```

---

## üìä Visualizaci√≥n de Resultados

### Boxplot por Grupos

```python
plt.figure(figsize=(10, 6))
df.boxplot(column='satisfaccion', by='area', grid=False, patch_artist=True)
plt.suptitle('')
plt.title('Distribuci√≥n de Satisfacci√≥n por √Årea', fontsize=14, fontweight='bold')
plt.xlabel('√Årea', fontsize=12)
plt.ylabel('Satisfacci√≥n', fontsize=12)
plt.tight_layout()
plt.show()
```

### Gr√°fico de Medias con Intervalos de Confianza

```python
# Calcular estad√≠sticos por grupo
medias = df.groupby('area')['satisfaccion'].mean()
std_errors = df.groupby('area')['satisfaccion'].sem()

plt.figure(figsize=(10, 6))
medias.plot(kind='bar', yerr=std_errors*1.96, capsize=5, color='steelblue', edgecolor='black')
plt.title('Media de Satisfacci√≥n por √Årea (IC 95%)', fontsize=14, fontweight='bold')
plt.xlabel('√Årea', fontsize=12)
plt.ylabel('Satisfacci√≥n Promedio', fontsize=12)
plt.xticks(rotation=0)
plt.axhline(y=df['satisfaccion'].mean(), color='red', linestyle='--', label='Media General')
plt.legend()
plt.grid(alpha=0.3, axis='y')
plt.tight_layout()
plt.show()
```

### Violin Plot

```python
plt.figure(figsize=(12, 6))
sns.violinplot(data=df, x='area', y='satisfaccion', palette='Set2')
plt.title('Distribuci√≥n de Satisfacci√≥n por √Årea (Violin Plot)', fontsize=14, fontweight='bold')
plt.xlabel('√Årea', fontsize=12)
plt.ylabel('Satisfacci√≥n', fontsize=12)
plt.grid(alpha=0.3, axis='y')
plt.tight_layout()
plt.show()
```

---

## üîç Pruebas Post-Hoc

Si rechazamos H‚ÇÄ en ANOVA, necesitamos **pruebas post-hoc** para determinar **qu√© grupos** son diferentes.

### Prueba de Tukey (HSD)

**La m√°s com√∫n:** Compara todas las parejas de medias controlando el error familiar.

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Realizar prueba de Tukey
tukey = pairwise_tukeyhsd(endog=df['satisfaccion'], groups=df['area'], alpha=0.05)

print("\nPrueba Post-Hoc de Tukey:")
print(tukey)

# Visualizaci√≥n
tukey.plot_simultaneous(figsize=(10, 6))
plt.title('Intervalos de Confianza 95% - Prueba de Tukey', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()
```

**Interpretaci√≥n de la tabla:**
- **reject:** True si hay diferencia significativa
- **meandiff:** Diferencia entre medias
- **lower/upper:** Intervalo de confianza de la diferencia
- **p-adj:** p-value ajustado

### Otras Pruebas Post-Hoc

#### Bonferroni (m√°s conservadora)

```python
from statsmodels.stats.multicomp import MultiComparison

mc = MultiComparison(df['satisfaccion'], df['area'])
resultado_bonferroni = mc.allpairtest(stats.ttest_ind, method='bonf')
print(resultado_bonferroni[0])
```

#### Scheff√© (m√°s flexible)

√ötil cuando se planean comparaciones complejas (no solo pares).

---

## üìà Estad√≠sticos Descriptivos por Grupo

```python
# Resumen por grupo
resumen = df.groupby('area')['satisfaccion'].agg([
    ('n', 'count'),
    ('Media', 'mean'),
    ('Mediana', 'median'),
    ('Desv.Std', 'std'),
    ('M√≠nimo', 'min'),
    ('M√°ximo', 'max')
]).round(2)

print("\nEstad√≠sticos Descriptivos por √Årea:")
print(resumen)

# Visualizar en tabla
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10, 4))
ax.axis('tight')
ax.axis('off')
tabla = ax.table(cellText=resumen.values,
                 rowLabels=resumen.index,
                 colLabels=resumen.columns,
                 cellLoc='center',
                 loc='center')
tabla.auto_set_font_size(False)
tabla.set_fontsize(10)
tabla.scale(1, 2)
plt.title('Resumen Estad√≠stico por √Årea', fontsize=14, fontweight='bold', pad=20)
plt.show()
```

---

## üéØ Tama√±o del Efecto

El p-value nos dice **SI** hay diferencia, pero no **QU√â TAN GRANDE** es.

### Eta Cuadrado (Œ∑¬≤)

Proporci√≥n de varianza en la variable dependiente explicada por la variable independiente.

```python
# Calcular Eta cuadrado
ss_between = sum([len(df[df['area']==a]) * (df[df['area']==a]['satisfaccion'].mean() - df['satisfaccion'].mean())**2
                  for a in df['area'].unique()])

ss_total = sum((df['satisfaccion'] - df['satisfaccion'].mean())**2)

eta_squared = ss_between / ss_total

print(f"\nEta¬≤ = {eta_squared:.4f}")

# Interpretaci√≥n
if eta_squared < 0.01:
    print("Efecto peque√±o")
elif eta_squared < 0.06:
    print("Efecto mediano")
else:
    print("Efecto grande")
```

---

## ‚ö†Ô∏è ¬øQu√© hacer si NO se cumplen los supuestos?

### 1. Si NO hay normalidad:

**Opci√≥n A:** Transformar datos
```python
# Transformaci√≥n logar√≠tmica
df['satisfaccion_log'] = np.log(df['satisfaccion'])

# Transformaci√≥n ra√≠z cuadrada
df['satisfaccion_sqrt'] = np.sqrt(df['satisfaccion'])
```

**Opci√≥n B:** Usar prueba NO param√©trica (Kruskal-Wallis)
```python
from scipy.stats import kruskal

norte = df[df['area'] == 'Norte']['satisfaccion']
sur = df[df['area'] == 'Sur']['satisfaccion']
este = df[df['area'] == 'Este']['satisfaccion']
oeste = df[df['area'] == 'Oeste']['satisfaccion']

h_stat, p_value = kruskal(norte, sur, este, oeste)

print(f"Kruskal-Wallis H: {h_stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("‚úó Al menos un grupo tiene mediana diferente")
    # Post-hoc: Mann-Whitney U con correcci√≥n Bonferroni
else:
    print("‚úì No hay diferencia entre medianas")
```

### 2. Si NO hay homogeneidad de varianzas:

**Usar Welch's ANOVA** (no asume varianzas iguales)
```python
# Welch's ANOVA ya est√° implementada en statsmodels
from scipy.stats import f_oneway

# Para Welch's ANOVA, usar pingouin
import pingouin as pg

welch_result = pg.welch_anova(data=df, dv='satisfaccion', between='area')
print(welch_result)
```

---

## üéØ Ejemplo Completo: An√°lisis de ONG

```python
import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar datos
df = pd.read_csv('ejemplo_satisfaccion_clientes.csv')

print("="*70)
print("AN√ÅLISIS ANOVA: SATISFACCI√ìN POR √ÅREA")
print("="*70)

# Paso 1: Estad√≠sticos descriptivos
print("\nEstad√≠sticos Descriptivos:")
resumen = df.groupby('area')['satisfaccion'].agg(['count', 'mean', 'std'])
print(resumen)

# Paso 2: Verificar supuestos
print("\n" + "="*70)
print("VERIFICACI√ìN DE SUPUESTOS")
print("="*70)

# Normalidad (Shapiro-Wilk por grupo)
print("\nPrueba de Normalidad (Shapiro-Wilk):")
for area in df['area'].unique():
    datos = df[df['area'] == area]['satisfaccion']
    stat, p = stats.shapiro(datos)
    resultado = "‚úì Normal" if p > 0.05 else "‚ö†Ô∏è No normal"
    print(f"  {area}: p={p:.4f} {resultado}")

# Homogeneidad de varianzas (Levene)
print("\nPrueba de Homogeneidad de Varianzas (Levene):")
grupos = [df[df['area'] == area]['satisfaccion'] for area in df['area'].unique()]
stat, p = stats.levene(*grupos)
print(f"  W={stat:.4f}, p={p:.4f}")
print(f"  {'‚úì Varianzas homog√©neas' if p > 0.05 else '‚ö†Ô∏è Varianzas NO homog√©neas'}")

# Paso 3: ANOVA
print("\n" + "="*70)
print("RESULTADO ANOVA")
print("="*70)

f_stat, p_value = stats.f_oneway(*grupos)
print(f"F-statistic: {f_stat:.4f}")
print(f"p-value: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    print(f"\n‚úó Rechazamos H‚ÇÄ (p={p_value:.4f} < {alpha})")
    print("Conclusi√≥n: Al menos una √°rea tiene satisfacci√≥n diferente")

    # Paso 4: Post-hoc (Tukey)
    print("\n" + "="*70)
    print("PRUEBAS POST-HOC (TUKEY)")
    print("="*70)

    tukey = pairwise_tukeyhsd(endog=df['satisfaccion'], groups=df['area'], alpha=0.05)
    print(tukey)

    # Identificar diferencias
    print("\nüìä Resumen de diferencias significativas:")
    for i, row in enumerate(tukey.summary().data[1:]):
        if row[6]:  # reject column
            print(f"  ‚Ä¢ {row[0]} vs {row[1]}: diferencia = {row[2]:.2f}, p={row[5]:.4f}")

else:
    print(f"\n‚úì No rechazamos H‚ÇÄ (p={p_value:.4f} ‚â• {alpha})")
    print("Conclusi√≥n: No hay diferencia significativa entre √°reas")

# Visualizaci√≥n
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Boxplot
df.boxplot(column='satisfaccion', by='area', ax=axes[0], patch_artist=True)
axes[0].set_title('Distribuci√≥n por √Årea', fontweight='bold')
axes[0].set_xlabel('√Årea')
axes[0].set_ylabel('Satisfacci√≥n')

# Gr√°fico de medias
medias = df.groupby('area')['satisfaccion'].mean()
std_errors = df.groupby('area')['satisfaccion'].sem()
medias.plot(kind='bar', yerr=std_errors*1.96, ax=axes[1], capsize=5, color='teal')
axes[1].set_title('Medias con IC 95%', fontweight='bold')
axes[1].set_ylabel('Satisfacci√≥n Promedio')
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)
axes[1].axhline(y=df['satisfaccion'].mean(), color='red', linestyle='--', label='Media General')
axes[1].legend()
axes[1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
```

---

## üí° Tips Pr√°cticos

### 1. Reportar Resultados

Al escribir resultados en un reporte:

```
Se realiz√≥ un ANOVA de un factor para comparar la satisfacci√≥n entre las 4 √°reas
de servicio (Norte, Sur, Este, Oeste). Se encontr√≥ una diferencia significativa
entre los grupos (F(3, 196) = 12.45, p < 0.001, Œ∑¬≤ = 0.16).

Pruebas post-hoc de Tukey revelaron que:
- √Årea Norte (M=8.45, SD=0.82) tuvo mayor satisfacci√≥n que √Årea Oeste (M=5.75, SD=0.85), p<0.001
- √Årea Este (M=9.20, SD=0.65) tuvo mayor satisfacci√≥n que √Årea Oeste, p<0.001
- No hubo diferencia significativa entre Norte y Sur (p=0.42)
```

### 2. Tama√±o Muestral

ANOVA requiere m√≠nimo ~20-30 observaciones por grupo para tener poder estad√≠stico adecuado.

### 3. ANOVA vs Regresi√≥n

ANOVA es un caso especial de regresi√≥n lineal cuando la variable independiente es categ√≥rica.

---

## üìö Referencias

- Levin & Rubin. "Estad√≠stica para administradores". Cap√≠tulo 10
- Montgomery, D. "Design and Analysis of Experiments"
- SciPy Documentation: `scipy.stats.f_oneway`
- Statsmodels Documentation: `statsmodels.stats.anova`

---

## ‚úçÔ∏è Ejercicios Propuestos

1. **Ejercicio 1:** Compara `calidad_atencion` entre las 4 √°reas
2. **Ejercicio 2:** Crea grupos de edad y compara satisfacci√≥n entre ellos
3. **Ejercicio 3:** Si alg√∫n supuesto no se cumple, aplica Kruskal-Wallis
4. **Ejercicio 4:** Calcula el tama√±o del efecto (Œ∑¬≤) y explica su significado pr√°ctico

