# Gu√≠a: Prueba Ji-Cuadrada (œá¬≤)

## üéØ ¬øQu√© es la Prueba Ji-Cuadrada?

La prueba **Ji-cuadrada (œá¬≤)** es una prueba estad√≠stica para determinar si existe una **relaci√≥n o asociaci√≥n** entre dos **variables categ√≥ricas**.

**Ejemplo de negocio:**
> ¬øEl √°rea de servicio (Norte, Sur, Este, Oeste) influye en el nivel de satisfacci√≥n (Baja, Media, Alta)?

---

## üìã Cu√°ndo Usar Ji-Cuadrada

‚úÖ **Usar cuando:**
- Ambas variables son **categ√≥ricas** (nominales u ordinales)
- Quieres probar independencia entre variables
- Tienes datos de frecuencias/conteos

‚ùå **NO usar cuando:**
- Variables son num√©ricas continuas (usar correlaci√≥n o regresi√≥n)
- Frecuencias esperadas < 5 en m√°s del 20% de celdas

---

## üßÆ Tipos de Pruebas Ji-Cuadrada

### 1. Prueba de Independencia
Determina si dos variables categ√≥ricas son independientes.

**Ejemplo:** ¬øEl g√©nero es independiente de la satisfacci√≥n?

### 2. Prueba de Bondad de Ajuste
Verifica si una distribuci√≥n observada se ajusta a una distribuci√≥n esperada.

**Ejemplo:** ¬øLos beneficiarios se distribuyen uniformemente entre √°reas?

---

## üìä Prueba Ji-Cuadrada de Independencia

### Paso 1: Plantear Hip√≥tesis

- **H‚ÇÄ:** Las variables son independientes (no hay relaci√≥n)
- **H‚ÇÅ:** Las variables NO son independientes (s√≠ hay relaci√≥n)

### Paso 2: Crear Tabla de Contingencia

Tabla que cruza las dos variables categ√≥ricas:

|            | Satisfacci√≥n Baja | Satisfacci√≥n Media | Satisfacci√≥n Alta | **Total** |
|------------|-------------------|---------------------|-------------------|-----------|
| Norte      | 5                 | 15                  | 30                | 50        |
| Sur        | 10                | 20                  | 20                | 50        |
| Este       | 3                 | 10                  | 37                | 50        |
| Oeste      | 20                | 25                  | 5                 | 50        |
| **Total**  | 38                | 70                  | 92                | **200**   |

### Paso 3: Calcular Frecuencias Esperadas

Frecuencia esperada = (Total fila √ó Total columna) / Total general

**Ejemplo:**
```
E(Norte, Baja) = (50 √ó 38) / 200 = 9.5
```

### Paso 4: Calcular Estad√≠stico œá¬≤

$$\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}$$

Donde:
- O = Frecuencia observada
- E = Frecuencia esperada

### Paso 5: Comparar con Valor Cr√≠tico

Grados de libertad: `df = (filas - 1) √ó (columnas - 1)`

Si **œá¬≤ > valor cr√≠tico** ‚Üí Rechazar H‚ÇÄ

---

## üíª Implementaci√≥n en Python

### Ejemplo Completo

```python
import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency
import seaborn as sns
import matplotlib.pyplot as plt

# Cargar datos
df = pd.read_csv('datos_satisfaccion.csv')

# Crear variable categ√≥rica de satisfacci√≥n
df['satisfaccion_cat'] = pd.cut(df['satisfaccion'],
                                  bins=[0, 6, 8, 10],
                                  labels=['Baja', 'Media', 'Alta'])

# Paso 1: Crear tabla de contingencia
tabla_contingencia = pd.crosstab(df['area'], df['satisfaccion_cat'])
print("Tabla de Contingencia:")
print(tabla_contingencia)

# Paso 2: Realizar prueba ji-cuadrada
chi2, p_value, dof, expected = chi2_contingency(tabla_contingencia)

# Resultados
print(f"\nEstad√≠stico œá¬≤: {chi2:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"Grados de libertad: {dof}")

# Decisi√≥n
alpha = 0.05
if p_value < alpha:
    print(f"\n‚úó Rechazamos H‚ÇÄ (p={p_value:.4f} < {alpha})")
    print("Conclusi√≥n: S√ç existe relaci√≥n entre √°rea y satisfacci√≥n")
else:
    print(f"\n‚úì No rechazamos H‚ÇÄ (p={p_value:.4f} ‚â• {alpha})")
    print("Conclusi√≥n: NO hay evidencia de relaci√≥n")

# Frecuencias esperadas
print("\nFrecuencias Esperadas:")
print(pd.DataFrame(expected,
                   index=tabla_contingencia.index,
                   columns=tabla_contingencia.columns))
```

---

## üìà Visualizaci√≥n de Resultados

### Heatmap de Frecuencias Observadas

```python
plt.figure(figsize=(10, 6))
sns.heatmap(tabla_contingencia, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Frecuencia'})
plt.title('Tabla de Contingencia: √Årea vs Satisfacci√≥n', fontsize=14, fontweight='bold')
plt.xlabel('Nivel de Satisfacci√≥n')
plt.ylabel('√Årea')
plt.tight_layout()
plt.show()
```

### Gr√°fico de Barras Apiladas

```python
tabla_contingencia.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='viridis')
plt.title('Distribuci√≥n de Satisfacci√≥n por √Årea', fontsize=14, fontweight='bold')
plt.xlabel('√Årea')
plt.ylabel('Frecuencia')
plt.legend(title='Satisfacci√≥n', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()
```

### Tabla de Proporciones

```python
# Proporciones por fila (% dentro de cada √°rea)
tabla_proporciones = tabla_contingencia.div(tabla_contingencia.sum(axis=1), axis=0) * 100
print("\nProporciones por √Årea (%):")
print(tabla_proporciones.round(2))
```

---

## üîç Interpretaci√≥n de Resultados

### Caso 1: p-value < 0.05

```
œá¬≤ = 45.32, p-value = 0.0001

‚úó Rechazamos H‚ÇÄ

Conclusi√≥n: Existe una relaci√≥n significativa entre el √°rea y la satisfacci√≥n.
Al observar la tabla, vemos que:
- √Årea Norte y Este tienen mayor proporci√≥n de satisfacci√≥n alta
- √Årea Oeste tiene mayor proporci√≥n de satisfacci√≥n baja
```

**Recomendaci√≥n:** Investigar las causas de estas diferencias. ¬øQu√© hace diferente al √Årea Norte?

### Caso 2: p-value ‚â• 0.05

```
œá¬≤ = 8.12, p-value = 0.2301

‚úì No rechazamos H‚ÇÄ

Conclusi√≥n: No hay evidencia suficiente de relaci√≥n entre √°rea y satisfacci√≥n.
La distribuci√≥n de satisfacci√≥n es similar en todas las √°reas.
```

**Recomendaci√≥n:** La satisfacci√≥n es consistente entre √°reas, lo cual es positivo para la estandarizaci√≥n del servicio.

---

## üìä Residuos Estandarizados

Los **residuos estandarizados** indican qu√© celdas contribuyen m√°s al estad√≠stico œá¬≤.

```python
# Calcular residuos estandarizados
residuos = (tabla_contingencia - expected) / np.sqrt(expected)

plt.figure(figsize=(10, 6))
sns.heatmap(residuos, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
            vmin=-3, vmax=3, cbar_kws={'label': 'Residuo Estandarizado'})
plt.title('Residuos Estandarizados', fontsize=14, fontweight='bold')
plt.xlabel('Nivel de Satisfacci√≥n')
plt.ylabel('√Årea')
plt.tight_layout()
plt.show()

# Interpretaci√≥n
print("\nInterpretaci√≥n de Residuos:")
print("  |residuo| > 2: Contribuci√≥n significativa")
print("  |residuo| > 3: Contribuci√≥n muy significativa")
```

**Residuos positivos:** M√°s casos observados de lo esperado
**Residuos negativos:** Menos casos observados de lo esperado

---

## ‚ö†Ô∏è Supuestos y Limitaciones

### Supuestos:
1. **Observaciones independientes:** Cada beneficiario aparece solo una vez
2. **Frecuencias esperadas ‚â• 5:** Al menos en el 80% de celdas
3. **Muestra aleatoria**

### Verificaci√≥n de Frecuencias Esperadas:

```python
# Contar celdas con frecuencia esperada < 5
celdas_total = expected.size
celdas_bajas = (expected < 5).sum()
porcentaje = (celdas_bajas / celdas_total) * 100

print(f"Celdas con E < 5: {celdas_bajas} de {celdas_total} ({porcentaje:.1f}%)")

if porcentaje > 20:
    print("‚ö†Ô∏è ADVERTENCIA: M√°s del 20% de celdas tienen E < 5")
    print("   Considerar combinar categor√≠as o usar Test Exacto de Fisher")
else:
    print("‚úì Supuesto cumplido")
```

### ¬øQu√© hacer si no se cumple?
- **Combinar categor√≠as:** Agrupar niveles con pocas observaciones
- **Test Exacto de Fisher:** Para tablas 2√ó2 con muestras peque√±as
- **Aumentar tama√±o muestral**

---

## üéØ Ejemplo Aplicado: ONG

### Pregunta de Investigaci√≥n:
¬øEl g√©nero de los beneficiarios est√° relacionado con si recomendar√≠an el servicio?

```python
# Crear tabla de contingencia
tabla = pd.crosstab(df['genero'], df['recomendaria'])

print("Tabla de Contingencia: G√©nero vs Recomendaci√≥n")
print(tabla)
print(f"\nTotal beneficiarios: {tabla.sum().sum()}")

# Prueba ji-cuadrada
chi2, p_value, dof, expected = chi2_contingency(tabla)

print(f"\nœá¬≤ = {chi2:.4f}")
print(f"p-value = {p_value:.4f}")

# Interpretaci√≥n
if p_value < 0.05:
    print("\n‚úó Hay relaci√≥n significativa entre g√©nero y recomendaci√≥n")

    # Analizar proporciones
    prop = tabla.div(tabla.sum(axis=1), axis=0) * 100
    print("\nProporciones (%):")
    print(prop.round(1))
else:
    print("\n‚úì No hay relaci√≥n entre g√©nero y recomendaci√≥n")
    print("   La tasa de recomendaci√≥n es similar entre g√©neros")
```

---

## üí° Tips Pr√°cticos

### 1. Categorizaci√≥n de Variables Num√©ricas
```python
# Convertir variable num√©rica a categ√≥rica
df['edad_grupo'] = pd.cut(df['edad'],
                          bins=[0, 30, 50, 100],
                          labels=['Joven', 'Adulto', 'Mayor'])
```

### 2. Comparar M√∫ltiples Grupos
```python
# Probar independencia entre 3+ grupos
tabla = pd.crosstab(df['area'], df['satisfaccion_cat'])
chi2, p, dof, exp = chi2_contingency(tabla)
```

### 3. Efecto del Tama√±o Muestral
Con muestras muy grandes, diferencias peque√±as pueden ser significativas estad√≠sticamente pero no relevantes en la pr√°ctica.

**Medida de asociaci√≥n (Cram√©r's V):**
```python
n = tabla.sum().sum()
min_dim = min(tabla.shape[0] - 1, tabla.shape[1] - 1)
cramers_v = np.sqrt(chi2 / (n * min_dim))

print(f"Cram√©r's V: {cramers_v:.4f}")

if cramers_v < 0.1:
    print("Asociaci√≥n d√©bil")
elif cramers_v < 0.3:
    print("Asociaci√≥n moderada")
else:
    print("Asociaci√≥n fuerte")
```

---

## üìö Referencias

- Levin & Rubin. "Estad√≠stica para administradores". Cap√≠tulo 11
- SciPy Documentation: `scipy.stats.chi2_contingency`
- Agresti, A. "Categorical Data Analysis"

---

## ‚úçÔ∏è Ejercicios Propuestos

1. **Ejercicio 1:** Prueba si hay relaci√≥n entre `area` y `recomendaria`
2. **Ejercicio 2:** Prueba si la distribuci√≥n de beneficiarios por √°rea es uniforme (bondad de ajuste)
3. **Ejercicio 3:** Crea grupos de edad y prueba relaci√≥n con satisfacci√≥n
4. **Ejercicio 4:** Calcula residuos estandarizados e identifica celdas at√≠picas

