# Gu√≠a: Regresi√≥n Lineal y Correlaci√≥n

## üéØ ¬øQu√© es Regresi√≥n Lineal?

La **regresi√≥n lineal** es un m√©todo estad√≠stico para modelar la **relaci√≥n** entre una variable dependiente (Y) y una o m√°s variables independientes (X).

**Objetivo:** Predecir el valor de Y bas√°ndose en X.

**Ejemplo de negocio:**
> ¬øPodemos predecir la satisfacci√≥n del cliente bas√°ndonos en el tiempo de espera?

---

## üìã Regresi√≥n Lineal Simple vs M√∫ltiple

### Regresi√≥n Lineal Simple
Una variable independiente (X) predice una variable dependiente (Y).

**Ecuaci√≥n:**
```
Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ
```

Donde:
- **Y:** Variable dependiente (satisfacci√≥n)
- **X:** Variable independiente (tiempo de espera)
- **Œ≤‚ÇÄ:** Intercepto (valor de Y cuando X=0)
- **Œ≤‚ÇÅ:** Pendiente (cambio en Y por cada unidad de X)
- **Œµ:** Error (residuo)

### Regresi√≥n Lineal M√∫ltiple
M√∫ltiples variables independientes predicen Y.

**Ecuaci√≥n:**
```
Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤‚ÇôX‚Çô + Œµ
```

---

## üìä Correlaci√≥n de Pearson

Antes de hacer regresi√≥n, es √∫til calcular la **correlaci√≥n** para ver qu√© tan fuerte es la relaci√≥n lineal.

### Coeficiente de Correlaci√≥n (r)

**Rango:** -1 a +1

- **r = +1:** Correlaci√≥n positiva perfecta
- **r = 0:** Sin correlaci√≥n lineal
- **r = -1:** Correlaci√≥n negativa perfecta

**Interpretaci√≥n:**
- |r| < 0.3: D√©bil
- 0.3 ‚â§ |r| < 0.7: Moderada
- |r| ‚â• 0.7: Fuerte

### Calcular en Python

```python
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar datos
df = pd.read_csv('datos_satisfaccion.csv')

# Correlaci√≥n de Pearson
r, p_value = stats.pearsonr(df['tiempo_espera'], df['satisfaccion'])

print(f"Coeficiente de correlaci√≥n (r): {r:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("‚úó La correlaci√≥n es estad√≠sticamente significativa")
else:
    print("‚úì No hay correlaci√≥n significativa")
```

### Scatter Plot

```python
plt.figure(figsize=(10, 6))
plt.scatter(df['tiempo_espera'], df['satisfaccion'], alpha=0.6, edgecolor='black')
plt.xlabel('Tiempo de Espera (minutos)', fontsize=12)
plt.ylabel('Satisfacci√≥n (1-10)', fontsize=12)
plt.title(f'Relaci√≥n: Tiempo de Espera vs Satisfacci√≥n (r={r:.3f})', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

---

## üíª Regresi√≥n Lineal Simple en Python

### Opci√≥n 1: Usando scipy

```python
from scipy import stats

# Variables
X = df['tiempo_espera']
Y = df['satisfaccion']

# Regresi√≥n lineal
pendiente, intercepto, r_value, p_value, std_err = stats.linregress(X, Y)

print("="*60)
print("REGRESI√ìN LINEAL SIMPLE")
print("="*60)
print(f"Ecuaci√≥n: Y = {intercepto:.4f} + ({pendiente:.4f})X")
print(f"R¬≤ = {r_value**2:.4f}")
print(f"p-value = {p_value:.4f}")
print(f"Error est√°ndar = {std_err:.4f}")
```

### Opci√≥n 2: Usando statsmodels (m√°s completo)

```python
import statsmodels.api as sm

# Preparar datos
X = df['tiempo_espera']
X = sm.add_constant(X)  # A√±adir intercepto
Y = df['satisfaccion']

# Ajustar modelo
modelo = sm.OLS(Y, X).fit()

# Resumen completo
print(modelo.summary())
```

**Interpretaci√≥n del summary:**
- **R-squared:** Proporci√≥n de varianza explicada
- **coef:** Coeficientes (Œ≤‚ÇÄ y Œ≤‚ÇÅ)
- **P>|t|:** p-value de cada coeficiente
- **[0.025  0.975]:** Intervalo de confianza 95%

---

## üìà Visualizaci√≥n de la Regresi√≥n

### L√≠nea de Regresi√≥n

```python
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.regplot(x='tiempo_espera', y='satisfaccion', data=df,
            scatter_kws={'alpha':0.5, 'edgecolor':'black'},
            line_kws={'color':'red', 'linewidth':2})

plt.xlabel('Tiempo de Espera (minutos)', fontsize=12)
plt.ylabel('Satisfacci√≥n (1-10)', fontsize=12)
plt.title('Regresi√≥n Lineal: Tiempo de Espera vs Satisfacci√≥n', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

### Predicciones vs Valores Reales

```python
# Hacer predicciones
predicciones = intercepto + pendiente * df['tiempo_espera']

plt.figure(figsize=(10, 6))
plt.scatter(df['satisfaccion'], predicciones, alpha=0.6, edgecolor='black')
plt.plot([df['satisfaccion'].min(), df['satisfaccion'].max()],
         [df['satisfaccion'].min(), df['satisfaccion'].max()],
         'r--', linewidth=2, label='Predicci√≥n perfecta')
plt.xlabel('Satisfacci√≥n Real', fontsize=12)
plt.ylabel('Satisfacci√≥n Predicha', fontsize=12)
plt.title('Valores Reales vs Predicciones', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

---

## üîç Interpretaci√≥n de Resultados

### Ejemplo de Output:

```
Ecuaci√≥n: Y = 10.2345 + (-0.0856)X
R¬≤ = 0.6234
p-value < 0.001
```

**Interpretaci√≥n en contexto de negocio:**

1. **Intercepto (Œ≤‚ÇÄ = 10.23):**
   > Cuando el tiempo de espera es 0 minutos, la satisfacci√≥n esperada es 10.23 (te√≥rico)

2. **Pendiente (Œ≤‚ÇÅ = -0.0856):**
   > Por cada minuto adicional de espera, la satisfacci√≥n disminuye 0.086 puntos
   > Si el tiempo de espera aumenta de 20 a 30 minutos, la satisfacci√≥n baja ~0.86 puntos

3. **R¬≤ = 0.6234:**
   > El 62.34% de la variabilidad en satisfacci√≥n se explica por el tiempo de espera
   > El 37.66% restante se debe a otros factores no medidos

4. **p-value < 0.001:**
   > La relaci√≥n es estad√≠sticamente significativa

---

## üìä R¬≤ (Coeficiente de Determinaci√≥n)

**R¬≤** indica qu√© proporci√≥n de la varianza en Y es explicada por X.

**Interpretaci√≥n:**
- R¬≤ = 0: X no explica nada de Y
- R¬≤ = 1: X explica perfectamente Y

**Valores t√≠picos:**
- Ciencias sociales: R¬≤ > 0.3 es aceptable
- Ciencias exactas: R¬≤ > 0.7 es deseable

### R¬≤ Ajustado

Para regresi√≥n m√∫ltiple, usar **R¬≤ ajustado** que penaliza agregar variables innecesarias.

```python
from sklearn.metrics import r2_score

# R¬≤ ajustado
n = len(df)  # N√∫mero de observaciones
k = 1        # N√∫mero de predictores

r2 = r_value**2
r2_ajustado = 1 - ((1 - r2) * (n - 1) / (n - k - 1))

print(f"R¬≤ = {r2:.4f}")
print(f"R¬≤ ajustado = {r2_ajustado:.4f}")
```

---

## ‚öôÔ∏è Supuestos de la Regresi√≥n Lineal

### 1. Linealidad
La relaci√≥n entre X e Y es lineal.

**Verificaci√≥n:** Scatter plot debe mostrar tendencia lineal

### 2. Independencia de Residuos
Los residuos no est√°n correlacionados.

**Verificaci√≥n:** Gr√°fico de residuos vs orden temporal

### 3. Homocedasticidad
La varianza de los residuos es constante.

**Verificaci√≥n:** Gr√°fico de residuos vs valores ajustados

```python
# Calcular residuos
residuos = df['satisfaccion'] - predicciones

plt.figure(figsize=(10, 6))
plt.scatter(predicciones, residuos, alpha=0.6, edgecolor='black')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Valores Ajustados', fontsize=12)
plt.ylabel('Residuos', fontsize=12)
plt.title('Gr√°fico de Residuos', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

**Patr√≥n ideal:** Puntos dispersos aleatoriamente alrededor de 0

### 4. Normalidad de Residuos
Los residuos siguen distribuci√≥n normal.

**Verificaci√≥n:** Q-Q plot

```python
from scipy import stats

stats.probplot(residuos, dist="norm", plot=plt)
plt.title('Q-Q Plot de Residuos', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```

### 5. No Multicolinealidad (para regresi√≥n m√∫ltiple)
Las variables independientes no est√°n altamente correlacionadas entre s√≠.

---

## üéØ Regresi√≥n Lineal M√∫ltiple

### Ejemplo: Predecir Satisfacci√≥n con M√∫ltiples Variables

```python
import statsmodels.api as sm

# Seleccionar variables predictoras
X = df[['tiempo_espera', 'calidad_atencion', 'tiempo_servicio']]
X = sm.add_constant(X)  # A√±adir intercepto
Y = df['satisfaccion']

# Ajustar modelo
modelo_multiple = sm.OLS(Y, X).fit()

# Resumen
print(modelo_multiple.summary())

# Ecuaci√≥n resultante
print("\nEcuaci√≥n de Regresi√≥n:")
print(f"Satisfacci√≥n = {modelo_multiple.params['const']:.4f}")
for var in ['tiempo_espera', 'calidad_atencion', 'tiempo_servicio']:
    signo = '+' if modelo_multiple.params[var] >= 0 else ''
    print(f"            {signo}{modelo_multiple.params[var]:.4f} * {var}")
```

**Interpretaci√≥n de coeficientes en regresi√≥n m√∫ltiple:**

```
Œ≤‚ÇÅ = -0.05 (tiempo_espera)
```
> Manteniendo constantes calidad_atencion y tiempo_servicio, un minuto adicional de espera reduce la satisfacci√≥n en 0.05 puntos.

---

## üîÆ Hacer Predicciones

### Predicci√≥n para Nuevos Datos

```python
# Datos de un nuevo cliente
nuevo_tiempo_espera = 25  # minutos

# Predicci√≥n
satisfaccion_predicha = intercepto + pendiente * nuevo_tiempo_espera

print(f"Si el tiempo de espera es {nuevo_tiempo_espera} minutos:")
print(f"  Satisfacci√≥n predicha: {satisfaccion_predicha:.2f}")

# Intervalo de confianza (m√°s complejo, usar statsmodels)
X_nuevo = sm.add_constant([nuevo_tiempo_espera])
prediccion = modelo.predict(X_nuevo)
print(f"  Predicci√≥n (statsmodels): {prediccion[0]:.2f}")
```

---

## üìâ Errores Comunes y Soluciones

### Error 1: Extrapolar M√°s All√° del Rango de Datos

**Problema:** Predecir para X fuera del rango observado

```python
print(f"Rango de tiempo_espera: {df['tiempo_espera'].min()} - {df['tiempo_espera'].max()}")

# ‚ùå MAL: Predecir para tiempo_espera = 100 (fuera del rango)
# ‚úÖ BIEN: Solo predecir dentro del rango observado
```

### Error 2: Asumir Causalidad

**Recuerda:** Correlaci√≥n ‚â† Causalidad

Aunque tiempo de espera y satisfacci√≥n est√©n correlacionados, no significa que uno **cause** el otro. Puede haber variables confusoras.

### Error 3: Ignorar Outliers

```python
# Identificar outliers usando distancia de Cook
from statsmodels.stats.outliers_influence import OLSInfluence

influence = OLSInfluence(modelo)
cooks_d = influence.cooks_distance[0]

# Puntos con Cook's D > 1 son influyentes
outliers_idx = np.where(cooks_d > 1)[0]
print(f"Outliers influyentes: {outliers_idx}")
```

---

## üí° Ejemplo Completo: An√°lisis de ONG

```python
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Cargar datos
df = pd.read_csv('ejemplo_satisfaccion_clientes.csv')

print("="*70)
print("AN√ÅLISIS DE REGRESI√ìN: TIEMPO DE ESPERA ‚Üí SATISFACCI√ìN")
print("="*70)

# Paso 1: Correlaci√≥n
r, p_cor = stats.pearsonr(df['tiempo_espera'], df['satisfaccion'])
print(f"\n1. CORRELACI√ìN")
print(f"   r = {r:.4f}")
print(f"   p-value = {p_cor:.4f}")

if abs(r) < 0.3:
    fuerza = "d√©bil"
elif abs(r) < 0.7:
    fuerza = "moderada"
else:
    fuerza = "fuerte"

direccion = "negativa" if r < 0 else "positiva"
print(f"   Correlaci√≥n {fuerza} {direccion}")

# Paso 2: Regresi√≥n Lineal Simple
X = sm.add_constant(df['tiempo_espera'])
Y = df['satisfaccion']
modelo = sm.OLS(Y, X).fit()

print(f"\n2. REGRESI√ìN LINEAL")
print(f"   Ecuaci√≥n: Y = {modelo.params['const']:.4f} + ({modelo.params['tiempo_espera']:.4f})X")
print(f"   R¬≤ = {modelo.rsquared:.4f}")
print(f"   R¬≤ ajustado = {modelo.rsquared_adj:.4f}")
print(f"   p-value = {modelo.f_pvalue:.4f}")

# Interpretaci√≥n
print(f"\n3. INTERPRETACI√ìN")
print(f"   ‚Ä¢ El {modelo.rsquared*100:.1f}% de la varianza en satisfacci√≥n se explica por tiempo de espera")
print(f"   ‚Ä¢ Por cada minuto adicional de espera, la satisfacci√≥n {'disminuye' if modelo.params['tiempo_espera'] < 0 else 'aumenta'} {abs(modelo.params['tiempo_espera']):.4f} puntos")

# Paso 3: Verificar supuestos
residuos = modelo.resid

print(f"\n4. VERIFICACI√ìN DE SUPUESTOS")

# Normalidad de residuos (Shapiro-Wilk)
stat_shapiro, p_shapiro = stats.shapiro(residuos)
print(f"   Normalidad (Shapiro-Wilk): p={p_shapiro:.4f} {'‚úì' if p_shapiro > 0.05 else '‚ö†Ô∏è'}")

# Paso 4: Visualizaciones
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Scatter con l√≠nea de regresi√≥n
axes[0, 0].scatter(df['tiempo_espera'], df['satisfaccion'], alpha=0.6, edgecolor='black')
axes[0, 0].plot(df['tiempo_espera'], modelo.predict(X), color='red', linewidth=2)
axes[0, 0].set_xlabel('Tiempo de Espera (min)')
axes[0, 0].set_ylabel('Satisfacci√≥n')
axes[0, 0].set_title(f'Regresi√≥n (R¬≤={modelo.rsquared:.3f})', fontweight='bold')
axes[0, 0].grid(alpha=0.3)

# Residuos vs Ajustados
axes[0, 1].scatter(modelo.fittedvalues, residuos, alpha=0.6, edgecolor='black')
axes[0, 1].axhline(y=0, color='red', linestyle='--')
axes[0, 1].set_xlabel('Valores Ajustados')
axes[0, 1].set_ylabel('Residuos')
axes[0, 1].set_title('Residuos vs Ajustados', fontweight='bold')
axes[0, 1].grid(alpha=0.3)

# Q-Q plot
stats.probplot(residuos, dist="norm", plot=axes[1, 0])
axes[1, 0].set_title('Q-Q Plot', fontweight='bold')
axes[1, 0].grid(alpha=0.3)

# Histograma de residuos
axes[1, 1].hist(residuos, bins=20, edgecolor='black', alpha=0.7)
axes[1, 1].set_xlabel('Residuos')
axes[1, 1].set_ylabel('Frecuencia')
axes[1, 1].set_title('Distribuci√≥n de Residuos', fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

# Paso 5: Predicci√≥n de ejemplo
print(f"\n5. EJEMPLO DE PREDICCI√ìN")
tiempo_ejemplo = 25
pred = modelo.params['const'] + modelo.params['tiempo_espera'] * tiempo_ejemplo
print(f"   Si tiempo_espera = {tiempo_ejemplo} min")
print(f"   ‚Üí Satisfacci√≥n predicha = {pred:.2f}")

print("\n" + "="*70)
```

---

## üìö Referencias

- Levin & Rubin. "Estad√≠stica para administradores". Cap√≠tulos 12-13
- Montgomery, D. "Introduction to Linear Regression Analysis"
- Statsmodels Documentation: `statsmodels.regression.linear_model`
- Scikit-learn Documentation: `sklearn.linear_model.LinearRegression`

---

## ‚úçÔ∏è Ejercicios Propuestos

1. **Ejercicio 1:** Modela la relaci√≥n entre `calidad_atencion` y `satisfaccion`
2. **Ejercicio 2:** Crea una regresi√≥n m√∫ltiple con 3+ variables predictoras
3. **Ejercicio 3:** Identifica outliers usando distancia de Cook
4. **Ejercicio 4:** Compara R¬≤ de diferentes modelos y elige el mejor

