# Gu√≠a de Limpieza de Datos con Python

## üìã √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Paso 1: Exploraci√≥n Inicial](#paso-1-exploraci√≥n-inicial)
3. [Paso 2: Valores Faltantes](#paso-2-valores-faltantes)
4. [Paso 3: Detecci√≥n de Outliers](#paso-3-detecci√≥n-de-outliers)
5. [Paso 4: Normalizaci√≥n de Formatos](#paso-4-normalizaci√≥n-de-formatos)
6. [Paso 5: Validaci√≥n de Tipos de Datos](#paso-5-validaci√≥n-de-tipos-de-datos)
7. [Paso 6: Documentaci√≥n de Transformaciones](#paso-6-documentaci√≥n-de-transformaciones)
8. [Checklist de Limpieza](#checklist-de-limpieza)

---

## Introducci√≥n

La limpieza de datos es un paso **cr√≠tico** en cualquier an√°lisis. Datos sucios pueden llevar a conclusiones err√≥neas. Esta gu√≠a te proporciona un proceso sistem√°tico para preparar tus datos.

### ¬øPor qu√© es importante?

- 80% del tiempo de an√°lisis se invierte en limpieza de datos
- Datos limpios = Resultados confiables
- Evita sesgos y errores en visualizaciones
- Facilita an√°lisis estad√≠sticos v√°lidos

---

## Paso 1: Exploraci√≥n Inicial

### 1.1 Cargar y Visualizar Datos

```python
import pandas as pd
import numpy as np

# Cargar dataset
df = pd.read_csv('datos.csv')

# Vista r√°pida
print("üìä Primeras filas:")
print(df.head())

print("\nüìè Dimensiones:")
print(f"Filas: {df.shape[0]}, Columnas: {df.shape[1]}")

print("\nüîç Informaci√≥n general:")
print(df.info())
```

### 1.2 Entender la Estructura

```python
# Tipos de datos
print("\nüìã Tipos de datos:")
print(df.dtypes)

# Nombres de columnas
print("\nüìù Columnas:")
print(df.columns.tolist())

# Estad√≠sticas descriptivas
print("\nüìà Resumen estad√≠stico:")
print(df.describe())
```

### 1.3 Identificar Problemas

```python
# Valores √∫nicos por columna
print("\nüî¢ Valores √∫nicos:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} valores √∫nicos")

# Duplicados
duplicados = df.duplicated().sum()
print(f"\n‚ö†Ô∏è Filas duplicadas: {duplicados}")
```

---

## Paso 2: Valores Faltantes

### 2.1 Detectar Valores Faltantes

```python
# Conteo de valores faltantes
print("\nüîç Valores faltantes por columna:")
missing = df.isnull().sum()
missing_pct = (missing / len(df)) * 100

missing_df = pd.DataFrame({
    'Columna': missing.index,
    'Faltantes': missing.values,
    'Porcentaje': missing_pct.values
})
print(missing_df[missing_df['Faltantes'] > 0])

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')
plt.title('Mapa de Valores Faltantes')
plt.show()
```

### 2.2 Estrategias de Tratamiento

#### Opci√≥n A: Eliminar

```python
# Eliminar filas con cualquier valor faltante
df_clean = df.dropna()

# Eliminar filas donde TODAS las columnas son nulas
df_clean = df.dropna(how='all')

# Eliminar columnas con m√°s de 50% de datos faltantes
threshold = 0.5
df_clean = df.dropna(thresh=int(threshold * len(df)), axis=1)
```

#### Opci√≥n B: Imputar

```python
# Imputar con la media (variables num√©ricas)
df['edad'].fillna(df['edad'].mean(), inplace=True)

# Imputar con la mediana (mejor para datos con outliers)
df['salario'].fillna(df['salario'].median(), inplace=True)

# Imputar con la moda (variables categ√≥ricas)
df['departamento'].fillna(df['departamento'].mode()[0], inplace=True)

# Imputar con valor espec√≠fico
df['comentarios'].fillna('Sin comentario', inplace=True)

# Forward fill (usar valor anterior)
df['temperatura'].fillna(method='ffill', inplace=True)

# Backward fill (usar valor siguiente)
df['temperatura'].fillna(method='bfill', inplace=True)
```

#### Opci√≥n C: Interpolaci√≥n

```python
# Interpolaci√≥n lineal (buena para series temporales)
df['ventas'] = df['ventas'].interpolate(method='linear')

# Interpolaci√≥n polinomial
df['ventas'] = df['ventas'].interpolate(method='polynomial', order=2)
```

### 2.3 Decisi√≥n Informada

```python
# Funci√≥n para decidir estrategia
def decidir_imputacion(columna, df):
    missing_pct = (df[columna].isnull().sum() / len(df)) * 100

    if missing_pct > 50:
        return f"‚ùå ELIMINAR columna '{columna}' (>{50}% faltantes)"
    elif missing_pct > 20:
        return f"‚ö†Ô∏è Revisar '{columna}' ({missing_pct:.1f}% faltantes)"
    elif df[columna].dtype in ['int64', 'float64']:
        return f"‚úì Imputar '{columna}' con mediana"
    else:
        return f"‚úì Imputar '{columna}' con moda"

# Aplicar
for col in df.columns:
    if df[col].isnull().sum() > 0:
        print(decidir_imputacion(col, df))
```

---

## Paso 3: Detecci√≥n de Outliers

### 3.1 M√©todo del Rango Intercuart√≠lico (IQR)

```python
def detectar_outliers_iqr(df, columna):
    """
    Detecta outliers usando el m√©todo IQR
    """
    Q1 = df[columna].quantile(0.25)
    Q3 = df[columna].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[columna] < lower_bound) | (df[columna] > upper_bound)]

    print(f"\nüìä Columna: {columna}")
    print(f"L√≠mite inferior: {lower_bound:.2f}")
    print(f"L√≠mite superior: {upper_bound:.2f}")
    print(f"Outliers detectados: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)")

    return outliers

# Ejemplo
outliers_edad = detectar_outliers_iqr(df, 'edad')
```

### 3.2 M√©todo Z-Score

```python
from scipy import stats

def detectar_outliers_zscore(df, columna, threshold=3):
    """
    Detecta outliers usando Z-score
    Z > 3 o Z < -3 se consideran outliers
    """
    z_scores = np.abs(stats.zscore(df[columna].dropna()))
    outliers_idx = np.where(z_scores > threshold)[0]

    print(f"\nüìä Columna: {columna}")
    print(f"Outliers (|Z| > {threshold}): {len(outliers_idx)}")

    return df.iloc[outliers_idx]

# Ejemplo
outliers_salario = detectar_outliers_zscore(df, 'salario')
```

### 3.3 Visualizaci√≥n de Outliers

```python
# Boxplot
plt.figure(figsize=(10, 6))
sns.boxplot(data=df[['edad', 'salario', 'satisfaccion']])
plt.title('Detecci√≥n Visual de Outliers')
plt.xticks(rotation=45)
plt.show()

# Scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(df.index, df['edad'], alpha=0.6)
plt.axhline(y=df['edad'].mean() + 3*df['edad'].std(), color='r', linestyle='--', label='L√≠mite superior')
plt.axhline(y=df['edad'].mean() - 3*df['edad'].std(), color='r', linestyle='--', label='L√≠mite inferior')
plt.title('Outliers en Edad')
plt.legend()
plt.show()
```

### 3.4 Tratamiento de Outliers

```python
# Opci√≥n 1: Eliminar
df_sin_outliers = df[df['edad'] <= upper_bound]

# Opci√≥n 2: Reemplazar con l√≠mite (capping)
df['edad_capped'] = df['edad'].clip(lower=lower_bound, upper=upper_bound)

# Opci√≥n 3: Transformaci√≥n logar√≠tmica
df['salario_log'] = np.log1p(df['salario'])

# Opci√≥n 4: Winsorizaci√≥n (reemplazar extremos con percentiles)
from scipy.stats.mstats import winsorize
df['edad_winsorized'] = winsorize(df['edad'], limits=[0.05, 0.05])
```

---

## Paso 4: Normalizaci√≥n de Formatos

### 4.1 Texto

```python
# Convertir a min√∫sculas
df['departamento'] = df['departamento'].str.lower()

# Eliminar espacios extra
df['nombre'] = df['nombre'].str.strip()

# Reemplazar valores
df['genero'] = df['genero'].replace({
    'M': 'Masculino',
    'F': 'Femenino',
    'H': 'Masculino',
    'M': 'Femenino'
})

# Estandarizar categor√≠as
df['ciudad'] = df['ciudad'].str.title()  # Primera letra may√∫scula
```

### 4.2 Fechas

```python
# Convertir a datetime
df['fecha_ingreso'] = pd.to_datetime(df['fecha_ingreso'], format='%Y-%m-%d', errors='coerce')

# Extraer componentes
df['a√±o'] = df['fecha_ingreso'].dt.year
df['mes'] = df['fecha_ingreso'].dt.month
df['dia_semana'] = df['fecha_ingreso'].dt.day_name()

# Calcular diferencias
df['antiguedad_dias'] = (pd.Timestamp.now() - df['fecha_ingreso']).dt.days
```

### 4.3 N√∫meros

```python
# Eliminar caracteres no num√©ricos
df['salario'] = df['salario'].str.replace('$', '').str.replace(',', '').astype(float)

# Redondear
df['calificacion'] = df['calificacion'].round(2)

# Convertir a enteros
df['edad'] = df['edad'].astype(int)
```

---

## Paso 5: Validaci√≥n de Tipos de Datos

### 5.1 Verificar Tipos Correctos

```python
# Diccionario de tipos esperados
tipos_esperados = {
    'id_empleado': 'int64',
    'nombre': 'object',
    'edad': 'int64',
    'salario': 'float64',
    'fecha_ingreso': 'datetime64[ns]',
    'activo': 'bool'
}

# Verificar
for col, tipo in tipos_esperados.items():
    if col in df.columns:
        tipo_actual = str(df[col].dtype)
        if tipo_actual != tipo:
            print(f"‚ö†Ô∏è {col}: esperado {tipo}, actual {tipo_actual}")
        else:
            print(f"‚úì {col}: {tipo}")
```

### 5.2 Convertir Tipos

```python
# A categ√≥rico (ahorra memoria)
df['departamento'] = df['departamento'].astype('category')

# A booleano
df['activo'] = df['activo'].map({'S√≠': True, 'No': False})

# A num√©rico (forzando errores a NaN)
df['edad'] = pd.to_numeric(df['edad'], errors='coerce')
```

### 5.3 Rangos V√°lidos

```python
# Funci√≥n de validaci√≥n
def validar_rangos(df, columna, min_val, max_val):
    invalidos = df[(df[columna] < min_val) | (df[columna] > max_val)]

    if len(invalidos) > 0:
        print(f"‚ö†Ô∏è {len(invalidos)} valores fuera de rango en '{columna}'")
        print(f"   Rango v√°lido: [{min_val}, {max_val}]")
        print(f"   Valores inv√°lidos: {invalidos[columna].tolist()}")
    else:
        print(f"‚úì '{columna}' dentro de rango [{min_val}, {max_val}]")

# Aplicar
validar_rangos(df, 'edad', 18, 100)
validar_rangos(df, 'satisfaccion', 1, 10)
```

---

## Paso 6: Documentaci√≥n de Transformaciones

### 6.1 Registro de Cambios

```python
import datetime

# Crear log de transformaciones
log_transformaciones = []

def registrar_transformacion(descripcion):
    """Registra cada transformaci√≥n aplicada"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_transformaciones.append({
        'timestamp': timestamp,
        'transformacion': descripcion
    })
    print(f"üìù [{timestamp}] {descripcion}")

# Ejemplo de uso
registrar_transformacion("Eliminadas 15 filas duplicadas")
registrar_transformacion("Imputada columna 'edad' con mediana (28 a√±os)")
registrar_transformacion("Detectados y eliminados 7 outliers en 'salario'")

# Exportar log
log_df = pd.DataFrame(log_transformaciones)
log_df.to_csv('log_limpieza_datos.csv', index=False)
```

### 6.2 Comparaci√≥n Antes/Despu√©s

```python
# Funci√≥n de resumen
def resumen_limpieza(df_original, df_limpio):
    """
    Compara dataset original vs limpio
    """
    print("=" * 60)
    print("üìä RESUMEN DE LIMPIEZA DE DATOS")
    print("=" * 60)

    print(f"\nüî¢ Dimensiones:")
    print(f"   Original: {df_original.shape}")
    print(f"   Limpio:   {df_limpio.shape}")
    print(f"   Filas eliminadas: {df_original.shape[0] - df_limpio.shape[0]}")
    print(f"   Columnas eliminadas: {df_original.shape[1] - df_limpio.shape[1]}")

    print(f"\n‚ùì Valores faltantes:")
    print(f"   Original: {df_original.isnull().sum().sum()}")
    print(f"   Limpio:   {df_limpio.isnull().sum().sum()}")

    print(f"\nüîÅ Duplicados:")
    print(f"   Original: {df_original.duplicated().sum()}")
    print(f"   Limpio:   {df_limpio.duplicated().sum()}")

    print("\n" + "=" * 60)

# Usar antes de guardar
resumen_limpieza(df_original, df_clean)
```

---

## Checklist de Limpieza

Use esta lista para verificar que todos los pasos se han completado:

### ‚úÖ Pre-Limpieza
- [ ] Dataset cargado correctamente
- [ ] Exploraci√≥n inicial completada
- [ ] Copia de respaldo creada (`df_original = df.copy()`)

### ‚úÖ Valores Faltantes
- [ ] Identificados valores faltantes
- [ ] Estrategia de imputaci√≥n decidida
- [ ] Transformaciones aplicadas y documentadas

### ‚úÖ Outliers
- [ ] Outliers detectados (IQR o Z-score)
- [ ] Visualizaciones creadas
- [ ] Decisi√≥n tomada (eliminar/transformar/mantener)

### ‚úÖ Formatos
- [ ] Texto normalizado (may√∫sculas/min√∫sculas)
- [ ] Fechas convertidas a datetime
- [ ] N√∫meros limpiados de caracteres especiales

### ‚úÖ Tipos de Datos
- [ ] Tipos verificados
- [ ] Conversiones aplicadas
- [ ] Rangos validados

### ‚úÖ Duplicados
- [ ] Duplicados identificados
- [ ] Duplicados eliminados (si aplica)

### ‚úÖ Documentaci√≥n
- [ ] Log de transformaciones creado
- [ ] Comparaci√≥n antes/despu√©s generada
- [ ] Dataset limpio exportado

### ‚úÖ Post-Limpieza
- [ ] Verificaci√≥n final de estructura
- [ ] Dataset guardado (`df_clean.to_csv('datos_limpios.csv', index=False)`)
- [ ] Notebook/script documentado con comentarios

---

## üìö Recursos Adicionales

**Libros:**
- "Python for Data Analysis" - Wes McKinney
- "Data Cleaning" - Ihab Ilyas & Xu Chu

**Documentaci√≥n:**
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)
- [Pandas Missing Data](https://pandas.pydata.org/docs/user_guide/missing_data.html)

**Tutoriales:**
- [Real Python: Data Cleaning](https://realpython.com/python-data-cleaning-numpy-pandas/)
- [Kaggle Learn: Data Cleaning](https://www.kaggle.com/learn/data-cleaning)

---

## üí° Consejos Finales

1. **Siempre haz una copia:** `df_clean = df.copy()` antes de modificar
2. **Documenta TODO:** Cada decisi√≥n debe estar justificada
3. **Visualiza primero:** Gr√°ficas revelan patrones que n√∫meros no muestran
4. **No elimines autom√°ticamente:** Analiza por qu√© faltan datos
5. **Valida con experto del dominio:** La limpieza requiere contexto del negocio
6. **Prueba diferentes estrategias:** Compara resultados de imputaci√≥n vs eliminaci√≥n
7. **Mant√©n versiones:** `datos_v1.csv`, `datos_v2_limpio.csv`

---

**√öltima actualizaci√≥n:** Enero 2025
**Curso:** CD2001B - Diagn√≥stico para L√≠neas de Acci√≥n
**Autor:** Tecnol√≥gico de Monterrey
